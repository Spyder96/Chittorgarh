{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "#from Database import MongoDB\n",
    "Headers=({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0' , 'Accept-language':'en-US , en;q=0.5'})\n",
    "URL = \"https://www.chittorgarh.com/report/mainboard-ipo-list-in-india-bse-nse/83/\"\n",
    "PRD_URL = \"https://www.chittorgarh.com/ipo/netweb-technologies-india-ipo/1459/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage_soup(URL):\n",
    "    try: \n",
    "        webpage=requests.get(URL,headers=Headers)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"-Page Unavailable : {e}\") \n",
    "    #Creating initial soup file\n",
    "    soup = BeautifulSoup(webpage.content,\"html.parser\")\n",
    "    return soup\n",
    "    #searching for product links available in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_webpage_soup(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"table\", attrs={'class': 'table table-bordered table-striped table-hover w-auto'})\n",
    "links = table.find_all('a')\n",
    "\n",
    "href_list = []\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    if href and href.startswith(\"https://www.chittorgarh.com/ipo/\"):\n",
    "        href_list.append(href)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def soup_table_data(table):\n",
    "    data = {}\n",
    "    if table is None:\n",
    "        data = {\"No Data Available\" : \"No Data\"}\n",
    "    else:\n",
    "        rows = table.find_all('tr')\n",
    "        if rows:\n",
    "            for row in rows:\n",
    "                cells = row.find_all(['th', 'td'])\n",
    "                for cell in cells:\n",
    "                    try:\n",
    "                        key = cells[0].text.strip()\n",
    "                    except:\n",
    "                        key = \"NA\"\n",
    "                    try:\n",
    "                        value = cell.text.strip()\n",
    "                    except:\n",
    "                        value = \"NA\"\n",
    "                    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('utf-8')\n",
    "                    value = re.sub(r'[^\\x00-\\x7F\\u20b9]+', '', value) \n",
    "                    value = re.sub(r'[^\\x00-\\x7F]+', '', value)  # Remove non-ASCII characters\n",
    "                    value = unidecode(value)\n",
    "                    key = re.sub(' ', '_' , key)\n",
    "                    data[key] = value\n",
    "        else:\n",
    "            data = {\"No Data Available\" : \"No data\"}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_ipo_data(soup):\n",
    "    company_name = soup.find('h2', itemprop='about', class_='border-bottom').text.replace(\" Details\",'')\n",
    "    tables = soup.find_all(\"table\", attrs={'class':\"table table-bordered table-striped table-hover w-auto\"})\n",
    "    all_table_data = {\"Company Name\": company_name}\n",
    "    for table in tables:\n",
    "        table_data = soup_table_data(table)\n",
    "        #print(table_data)\n",
    "        all_table_data.update(table_data)\n",
    "    json_data = json.dumps(all_table_data,indent=4)\n",
    "    with open(f'{company_name}.json', 'w') as file:\n",
    "        json.dump(all_table_data, file, indent=4, ensure_ascii= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in href_list:\n",
    "    ipo_soup = get_webpage_soup(link)\n",
    "    extract_ipo_data(ipo_soup)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
