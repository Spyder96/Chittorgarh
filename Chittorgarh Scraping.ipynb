{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "#from Database import MongoDB\n",
    "Headers=({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0' , 'Accept-language':'en-US , en;q=0.5'})\n",
    "URL = \"https://www.chittorgarh.com/report/mainboard-ipo-list-in-india-bse-nse/83/\"\n",
    "PRD_URL = \"https://www.chittorgarh.com/ipo/netweb-technologies-india-ipo/1459/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage_soup(URL):\n",
    "    try: \n",
    "        webpage=requests.get(URL,headers=Headers)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"-Page Unavailable : {e}\") \n",
    "    #Creating initial soup file\n",
    "    soup = BeautifulSoup(webpage.content,\"html.parser\")\n",
    "    return soup\n",
    "    #searching for product links available in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_webpage_soup(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"table\", attrs={'class': 'table table-bordered table-striped table-hover w-auto'})\n",
    "links = table.find_all('a')\n",
    "\n",
    "href_list = []\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    if href and href.startswith(\"https://www.chittorgarh.com/ipo/\"):\n",
    "        href_list.append(href)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def soup_table_data(table):\n",
    "    data = {}\n",
    "    if table is None:\n",
    "        data = {\"No Data Available\" : \"No Data\"}\n",
    "    else:\n",
    "        rows = table.find_all('tr')\n",
    "        if rows:\n",
    "            for row in rows:\n",
    "                cells = row.find_all(['th', 'td'])\n",
    "                for cell in cells:\n",
    "                    try:\n",
    "                        key = cells[0].text.strip()\n",
    "                    except:\n",
    "                        key = \"NA\"\n",
    "                    try:\n",
    "                        value = cell.text.strip()\n",
    "                    except:\n",
    "                        value = \"NA\"\n",
    "                    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('utf-8')\n",
    "                    value = re.sub(r'[^\\x00-\\x7F\\u20b9]+', '', value) \n",
    "                    value = re.sub(r'[^\\x00-\\x7F]+', '', value)  # Remove non-ASCII characters\n",
    "                    value = unidecode(value)\n",
    "                    key = re.sub(' ', '_' , key)\n",
    "                    data[key] = value\n",
    "        else:\n",
    "            data = {\"No Data Available\" : \"No data\"}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_ipo_data(soup):\n",
    "    company_name = soup.find('h2', itemprop='about', class_='border-bottom').text.replace(\" Details\",'')\n",
    "    tables = soup.find_all(\"table\", attrs={'class':\"table table-bordered table-striped table-hover w-auto\"})\n",
    "    all_table_data = {\"Company Name\": company_name}\n",
    "    for table in tables:\n",
    "        table_data = soup_table_data(table)\n",
    "        #print(table_data)\n",
    "        all_table_data.update(table_data)\n",
    "    json_data = json.dumps(all_table_data,indent=4)\n",
    "    with open(f'{company_name}.json', 'w') as file:\n",
    "        json.dump(all_table_data, file, indent=4, ensure_ascii= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in href_list:\n",
    "    ipo_soup = get_webpage_soup(link)\n",
    "    extract_ipo_data(ipo_soup)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables scraped and stored in JSON format.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "\n",
    "url = 'https://www.chittorgarh.com/ipo/tvs-supply-chain-solutions-ipo/1475/'\n",
    "Headers=({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0' , 'Accept-language':'en-US , en;q=0.5'})\n",
    "response = requests.get(url, headers=Headers)\n",
    "tables = pd.read_html(response.text)\n",
    "data = {}  # Dictionary to store tables\n",
    "\n",
    "# Loop through each DataFrame and store them in the dictionary\n",
    "for i, table_df in enumerate(tables):\n",
    "    table_name = f\"table_{i+1}\"\n",
    "    data[table_name] = table_df.to_dict(orient='records')\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open('tables_data.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4, ensure_ascii= False)\n",
    "\n",
    "print(\"Tables scraped and stored in JSON format.\")\n",
    "\n",
    "combined_data = []\n",
    "for table_df in tables:\n",
    "    table_data = table_df.to_dict(orient='records')\n",
    "    combined_data.extend(table_data)\n",
    "\n",
    "# Save the combined list of dictionaries as a JSON file\n",
    "with open('combined_tables_data.json', 'w') as json_file:\n",
    "    json.dump(combined_data, json_file, indent=4 , ensure_ascii = False)\n",
    "original_data = combined_data\n",
    "transformed_data = {}\n",
    "\n",
    "# Iterate through the original data\n",
    "for item in original_data:\n",
    "    if 0 in item and 1 in item:\n",
    "        # Handle key-value pairs\n",
    "        key = item[0]\n",
    "        value = item[1]\n",
    "        transformed_data[key] = value\n",
    "    elif 'Application' in item:\n",
    "        # Handle applications\n",
    "        application_type = item['Application']\n",
    "        application_info = {\n",
    "            'Lots': item['Lots'],\n",
    "            'Shares': item['Shares'],\n",
    "            'Amount': item['Amount']\n",
    "        }\n",
    "        if 'Applications' not in transformed_data:\n",
    "            transformed_data['Applications'] = []\n",
    "        transformed_data['Applications'].append({application_type: application_info})\n",
    "    elif 'KPI' in item:\n",
    "        # Handle KPIs\n",
    "        kpi = item['KPI']\n",
    "        value = item['Values']\n",
    "        if 'Key_Performance_Indicators' not in transformed_data:\n",
    "            transformed_data['Key_Performance_Indicators'] = {}\n",
    "        transformed_data['Key_Performance_Indicators'][kpi] = value\n",
    "    elif 'Category' in item:\n",
    "        # Handle subscription details\n",
    "        category = item['Category']\n",
    "        subscription = item['Subscription (times)']\n",
    "        if 'Subscription_Details' not in transformed_data:\n",
    "            transformed_data['Subscription_Details'] = []\n",
    "        transformed_data['Subscription_Details'].append({category: subscription})\n",
    "    elif 'Review By' in item:\n",
    "        # Handle reviews\n",
    "        review_type = item['Review By']\n",
    "        review_data = {\n",
    "            'Subscribe': item['Subscribe'],\n",
    "            'Neutral': item['Neutral'],\n",
    "            'Avoid': item['Avoid']\n",
    "        }\n",
    "        if 'Reviews' not in transformed_data:\n",
    "            transformed_data['Reviews'] = {}\n",
    "        transformed_data['Reviews'][review_type] = review_data\n",
    "    else:\n",
    "        # Handle other cases\n",
    "        # Add custom logic here based on your data structure\n",
    "        pass\n",
    "\n",
    "# Save the combined list of dictionaries as a JSON file\n",
    "with open('transformed_combined_tables_data.json', 'w') as json_file:\n",
    "    json.dump(transformed_data, json_file, indent=4 , ensure_ascii = False)\n",
    "with open('transformed_combined_tables_data.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "\n",
    "\n",
    "# Flatten nested structures using json_normalize\n",
    "flattened_data = json_normalize(json_data, sep='_')\n",
    "# Flatten the nested \"Applications\" list\n",
    "applications = flattened_data.pop('Applications')  # Remove the original \"Applications\" column\n",
    "for i, app in enumerate(applications[0]):\n",
    "    k = list(applications[0][i].keys())[0]\n",
    "    if k == \"Lot Size Calculator\":\n",
    "        continue\n",
    "    app_data = list(app.values())[0]  # Get the application data dictionary\n",
    "    for key, value in app_data.items():\n",
    "        flattened_data[f'Applications_{k}_{key}'] = value\n",
    "\n",
    "        \n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IPO Date</th>\n",
       "      <td>Aug 10, 2023 to Aug 14, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Listing Date</th>\n",
       "      <td>Wednesday, 23 August 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Face Value</th>\n",
       "      <td>₹1 per share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>₹187 to ₹197 per share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Size</th>\n",
       "      <td>76 Shares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applications_S-HNI (Max)_Shares</th>\n",
       "      <td>5016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applications_S-HNI (Max)_Amount</th>\n",
       "      <td>₹988,152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applications_B-HNI (Min)_Lots</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applications_B-HNI (Min)_Shares</th>\n",
       "      <td>5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applications_B-HNI (Min)_Amount</th>\n",
       "      <td>₹1,003,124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0\n",
       "IPO Date                         Aug 10, 2023 to Aug 14, 2023\n",
       "Listing Date                        Wednesday, 23 August 2023\n",
       "Face Value                                       ₹1 per share\n",
       "Price                                  ₹187 to ₹197 per share\n",
       "Lot Size                                            76 Shares\n",
       "...                                                       ...\n",
       "Applications_S-HNI (Max)_Shares                          5016\n",
       "Applications_S-HNI (Max)_Amount                      ₹988,152\n",
       "Applications_B-HNI (Min)_Lots                              67\n",
       "Applications_B-HNI (Min)_Shares                          5092\n",
       "Applications_B-HNI (Min)_Amount                    ₹1,003,124\n",
       "\n",
       "[65 rows x 1 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
